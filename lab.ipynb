{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5d5c7c",
   "metadata": {},
   "source": [
    "Problem: Predicting Telecom Customer Churn\n",
    "\n",
    "# Introduction to the Business Scenario\n",
    "You are a data scientist at a telecom company facing a growing challenge with customer churn. \n",
    "Over the past year, the company has observed a significant number of customers switching to competitors, leading to reduced revenue and an increase in customer acquisition costs. \n",
    "Management is keen to identify at-risk customers early and implement targeted retention strategies to minimize churn.\n",
    "\n",
    "As part of the solution, you have been tasked with leveraging machine learning to predict customer churn. By accurately identifying customers who are likely to leave, the company can take proactive steps, such as offering incentives, discounts, or improved services, to retain these customers.\n",
    "\n",
    "# About This Dataset\n",
    "The dataset represents telecom customer records and includes demographic, account, and service information. It is designed to help predict whether a customer will churn or not. The dataset includes 7,043 unique customer entries with 21 attributes.\n",
    "\n",
    "Features\n",
    "- Customer Demographics:\n",
    "    - gender: Gender of the customer (Male/Female).\n",
    "    - SeniorCitizen: Indicates whether the customer is a senior citizen (1 for Yes, 0 for No).\n",
    "    - Partner: Indicates if the customer has a partner (Yes/No).\n",
    "    - Dependents: Indicates if the customer has dependents (Yes/No).\n",
    "- Account Information:\n",
    "    - tenure: Number of months the customer has been with the company.\n",
    "    - MonthlyCharges: Monthly charges incurred by the customer.\n",
    "    - TotalCharges: Total charges incurred by the customer.\n",
    "- Services Availed:\n",
    "    - PhoneService: Indicates if the customer has a phone service (Yes/No).\n",
    "    - MultipleLines: Indicates if the customer has multiple lines (Yes, No, No phone service).\n",
    "    - InternetService: Type of internet service (DSL, Fiber optic, No).\n",
    "    - OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport: Whether the customer has availed of these specific internet services (Yes, No, No internet service).\n",
    "    - StreamingTV, StreamingMovies: Indicates if the customer uses streaming services (Yes, No, No internet service).\n",
    "- Contract and Payment Information:\n",
    "    - Contract: Type of contract (Month-to-month, One year, Two year).\n",
    "    - PaperlessBilling: Indicates if the customer uses paperless billing (Yes/No).\n",
    "    - PaymentMethod: Payment method used by the customer (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)).\n",
    "- Target Variable:\n",
    "    - Churn: Indicates whether the customer has churned (Yes/No).\n",
    "\n",
    "Dataset Overview\n",
    "\n",
    "This dataset was made publicly available on Kaggle under the name \"Telco Customer Churn\" by Blastchar. It provides valuable insights for building a predictive model to address customer retention challenges in the telecom industry.\n",
    "\n",
    "Rows: 7,043\n",
    "Columns: 21\n",
    "Target Variable: Churn (binary classification: Yes/No)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b487f",
   "metadata": {},
   "source": [
    "# Step 1: Problem formulation and data collection\n",
    "\n",
    "Start this project off by writing a few sentences below that summarize the business problem and the business goal you're trying to achieve in this scenario. Include a business metric you would like your team to aspire toward. With that information defined, clearly write out the machine learning problem statement. Finally, add a comment or two about the type of machine learning this represents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e09af",
   "metadata": {},
   "source": [
    "### Read through a business scenario and:\n",
    "\n",
    "### 1. Determine if and why ML is an appropriate solution to deploy.\n",
    "\\# Write your answer here\n",
    "\n",
    "### 2. Formulate the business problem, success metrics, and desired ML output.\n",
    "\\# Write your answer here\n",
    "\n",
    "### 3. Identify the type of ML problem you’re dealing with.\n",
    "\\# Write your answer here\n",
    "\n",
    "### 4. Analyze the appropriateness of the data you’re working with.\n",
    "\\# Write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a5ad2",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Now that we have decided where to focus our energy, let's set things up so you can start working on solving the problem.\n",
    "\n",
    "\n",
    "Replace **`<LabBucketName>`** with the resource name that was provided with your lab account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75c6b6-5e6f-4ab6-9601-a8593514fe62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = '<LabBucketName>'  # specify your bucket name\n",
    "prefix = 'telco-churn-example'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6830ffd",
   "metadata": {},
   "source": [
    "# Step 2: Data preprocessing   \n",
    "In this data preprocessing phase, you should take the opportunity to explore  your data to better understand it. First, import the necessary libraries and read the data into a Pandas dataframe. After that, explore your data. Look for the shape of the dataset and explore your columns and the types of columns you're working with (numerical, categorical). Consider performing basic statistics on the features to get a sense of feature means and ranges. Take a close look at your target column and determine its distribution.\n",
    "\n",
    "### Specific questions to consider\n",
    "1. What can you deduce from the basic statistics you ran on the features? \n",
    "\n",
    "2. What can you deduce from the distributions of the target classes?\n",
    "\n",
    "3. Is there anything else you deduced from exploring the data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464d7b0",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('<CODE>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f04f45",
   "metadata": {},
   "source": [
    "Check the dataframe by printing the first 5 rows of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41baf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b82b7a",
   "metadata": {},
   "source": [
    "**Question**: What can you find out about the column types and the null values? How many columns are numerical or categorical? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b727ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54e69c",
   "metadata": {},
   "source": [
    "Check for missing values in the dataset. \n",
    "Convert the Total Charges column to numeric values replacing any missing values with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175594e6-d076-46cb-b63a-12696e87352b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'TotalCharges' to numeric, and handle non-numeric values\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45610e9",
   "metadata": {},
   "source": [
    "Drop the columns that do not provide any value to the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e68b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Drop 'customerID' column\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667e0e0",
   "metadata": {},
   "source": [
    "Convert binary variables like Churn (Yes/No) into numeric (0/1).Apply one-hot encoding for non-binary categorical variables like Contract (e.g., Monthly, Yearly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c04a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode binary categorical columns\n",
    "<CODE>\n",
    "\n",
    "# One-hot encode multi-category columns\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d706c0-effb-4337-a815-c59984b05656",
   "metadata": {},
   "source": [
    "Scale numerical columns (tenure, MonthlyCharges, TotalCharges) using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11317e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standardize numerical columns\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0777b-dbbf-414d-a6db-8bca75a2fff5",
   "metadata": {},
   "source": [
    "Observe the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c07f3-51ef-48ab-8813-5e4f845829a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b651eef",
   "metadata": {},
   "source": [
    "# Step 3: Model training and evaluation\n",
    "Set up Sagemaker session and role. Specify your bucket and a prefix to store the output.\n",
    "Lets start by instantiating the LinearLearner estimator with `predictor_type='binary_classifier'` parameter with one ml.m5.large instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbbe86-a282-4fe0-b248-53f033102ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.amazon.linear_learner import LinearLearner \n",
    "\n",
    "# Set up SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()  # Ensure this role has the required permissions\n",
    "bucket = '<LabBucketName>'       # Replace with your S3 bucket name\n",
    "prefix = 'telco-churn-linear-learner'         # S3 prefix for data storage\n",
    "\n",
    "# Instantiate the LinearLearner estimator with an instance type of ml.m5large\n",
    "linear = LinearLearner(\n",
    "    role=role,\n",
    "    instance_count=<CODE>,\n",
    "    instance_type='<CODE>',\n",
    "    predictor_type='<CODE>',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd1ae3",
   "metadata": {},
   "source": [
    "Sagemaker's Linear Learner requires input data to be numeric. \n",
    "Convert the numerical columns to float32\n",
    "Split data into features and target. Further, split it in training, validation and test sets.\n",
    "Convert all these data sets to NumPy arrays with float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea77d5-3701-45ba-aac3-037699fb5604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume `telco_data` is the dataset, and `Churn` is the target column.\n",
    "telco_data = data\n",
    "# Step 1: Convert all numerical columns to float32\n",
    "<CODE>\n",
    "\n",
    "# Ensure the target variable ('Churn') is also float32\n",
    "<CODE>\n",
    "\n",
    "# Step 2: Split data into features (X) and target (y)\n",
    "<CODE>\n",
    "\n",
    "# Step 3: Split the dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = <CODE>\n",
    "X_val, X_test, y_val, y_test = <CODE>\n",
    "\n",
    "# Step 4: Convert train, validation, and test sets to NumPy arrays with float32\n",
    "train_features = <CODE>\n",
    "train_labels = <CODE>\n",
    "val_features = <CODE>\n",
    "val_labels = <CODE>\n",
    "test_features = <CODE>\n",
    "test_labels = <CODE>\n",
    "\n",
    "# Step 5: Verify the data types\n",
    "print(f\"Train features dtype: {train_features.dtype}, Train labels dtype: {train_labels.dtype}\")\n",
    "print(f\"Validation features dtype: {val_features.dtype}, Validation labels dtype: {val_labels.dtype}\")\n",
    "print(f\"Test features dtype: {test_features.dtype}, Test labels dtype: {test_labels.dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a363c",
   "metadata": {},
   "source": [
    "Linear learner accepts training data in protobuf or CSV content types, and accepts inference requests in protobuf, CSV, or JSON content types. Training data has features and ground-truth labels, while the data in an inference request has only features. In a production pipeline, it is recommended to convert the data to the Amazon SageMaker protobuf format and store it in Amazon S3. However, to get up and running quickly, AWS provides the convenient method `record_set` for converting and uploading when the dataset is small enough to fit in local memory. It accepts NumPy arrays like the ones you already have, so let's use it here. The `RecordSet` object will keep track of the temporary Amazon S3 location of your data. Use the `estimator.record_set` function to create train, validation, and test records. Then, use the `estimator.fit` function to start your training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbc557e-ef1a-4336-9f96-820d9876e6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create RecordSet for train, validation, and test datasets\n",
    "train_records = linear.record_set(train_features, train_labels, channel='train')\n",
    "val_records = linear.record_set(val_features, val_labels, channel='validation')\n",
    "test_records = linear.record_set(test_features, test_labels, channel='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527323fc-0183-4982-8163-21890e1b223e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a52acd",
   "metadata": {},
   "source": [
    "#Model Evaluation \n",
    "In this section, you'll evaluate your trained model. First, use the `estimator.deploy` function with `initial_instance_count= 1` and `instance_type= 'ml.m5.large'` to deploy your model on Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ed040-2da4-46a7-8912-699a6729a07a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "linear_predictor = linear.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b9ee0c",
   "metadata": {},
   "source": [
    "Check if your endpoint is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790f247-e4cc-426d-8231-43f23db7de9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# Check endpoint status\n",
    "response = sm_client.describe_endpoint(EndpointName='your-endpoint-name')\n",
    "print(\"Endpoint status:\", response['EndpointStatus'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705d814",
   "metadata": {},
   "source": [
    "Serialize the test features in CSV format and verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12b2c2-0c4a-42c1-8c5d-095e5619f77e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1.0,0.0,1.0,0.0,1.0436162,1.0,1.0,-0.16158292,0.5400106,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "0.0,0.0,0.0,0.0,-1.1145631,1.0,0.0,0.34526518,-0.83407307,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,0.0,1.0\n",
      "1.0,0.0,1.0,1.0,0.8807347,1.0,1.0,-1.3298262,-0.41488805,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,1.0,0.0,1.0,0.0,1.0,0.0\n",
      "0.0,0.0,1.0,1.0,1.6137012,1.0,1.0,1.6381432,2.7311187,1.0,0.0,0.0,1.0,1.0,0.0\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "# Serialize test features into CSV format\n",
    "<CODE>\n",
    "\n",
    "# Verify the serialized CSV data\n",
    "print(type(test_csv_data))  # Ensure this is a string\n",
    "print(test_csv_data[:500])  # Preview first 500 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d236ba9-0235-4054-b937-728e5e9c154a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Create a predictor for the endpoint\n",
    "<CODE>\n",
    "\n",
    "# Perform inference\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c5aba-b7db-4d4c-9211-6ad0cf5e16b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example raw predictions (byte string from SageMaker endpoint)\n",
    "raw_predictions = predictions\n",
    "# Step 1: Decode and parse the byte string\n",
    "decoded_predictions = <CODE>\n",
    "parsed_predictions = <CODE>\n",
    "# Step 2: Extract scores and predicted labels\n",
    "predictions_list = <CODES>\n",
    "scores = <CODE>\n",
    "predicted_labels = <CODE>\n",
    "# Step 3: Convert scores to binary labels using a threshold\n",
    "threshold = 0.5\n",
    "y_pred = <CODE>\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", scores[0])\n",
    "print(\"Predicted Labels (from model):\", predicted_labels[0])\n",
    "print(\"Binary Labels (custom threshold):\", y_pred[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5511132",
   "metadata": {},
   "source": [
    "### Understanding the Confusion Matrix for Telecom Churn\n",
    "The confusion matrix helps us evaluate how well our model predicts customer churn by breaking down predictions into four critical business scenarios:\n",
    "\n",
    "1. True Negatives: Loyal customers correctly identified\n",
    "  - These are customers we correctly predicted would stay\n",
    "  - No unnecessary retention resources spent\n",
    "  - Represents efficient resource allocation\n",
    "\n",
    "2. False Positives: Unnecessary interventions\n",
    "  - Customers wrongly flagged as likely to leave\n",
    "  - Represents potentially wasted retention budget\n",
    "  - Could annoy satisfied customers with unnecessary retention offers\n",
    "\n",
    "3. False Negatives: Missed opportunities\n",
    "  - Customers who left without us predicting it\n",
    "  - Most costly error: lost revenue + customer acquisition costs\n",
    "  - No chance to intervene with retention offers\n",
    "\n",
    "4. True Positives: Successful early warnings\n",
    "  - Correctly identified customers at risk of leaving\n",
    "  - Allows proactive retention measures\n",
    "  - Prime opportunities for targeted intervention\n",
    "\n",
    "Business Insights to Look For:\n",
    "- Ratio of correctly identified churners vs total actual churners\n",
    "- Efficiency rate of retention targeting (true positives vs all positive predictions)\n",
    "- Number of missed churning customers and potential revenue impact\n",
    "- Balance between identifying loyal customers vs identifying churners\n",
    "\n",
    "Key Business Decisions:\n",
    "1. Model threshold adjustment based on costs of false positives vs false negatives\n",
    "2. Resource allocation for retention campaigns\n",
    "3. Cost-benefit analysis of retention actions vs potential customer loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9835c1a-11cc-4249-a4c4-a75fb7812c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate confusion matrix\n",
    "<CODE>\n",
    "\n",
    "# Plot confusion matrix\n",
    "<CODE>\n",
    "# Print classification report\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ae711",
   "metadata": {},
   "source": [
    "### Understanding ROC-AUC\n",
    "The ROC (Receiver Operating Characteristic) curve plots the True Positive Rate against False Positive Rate at various thresholds. It's particularly useful for churn prediction because:\n",
    "- It's insensitive to class imbalance (common in churn data where most customers don't churn)\n",
    "- AUC score range interpretation:\n",
    "  - 0.9-1.0: Excellent prediction\n",
    "  - 0.8-0.9: Good prediction\n",
    "  - 0.7-0.8: Fair prediction\n",
    "  - < 0.7: Poor prediction\n",
    "- Helps choose optimal threshold for classifying churners\n",
    "\n",
    "Look for a curve that rises sharply and stays close to the top-left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Parse the predictions from bytes to JSON\n",
    "<CODE>\n",
    "\n",
    "# Extract probability scores for the positive class (churn)\n",
    "<CODE>\n",
    "\n",
    "# Calculate ROC curve and ROC-AUC score\n",
    "<CODE>\n",
    "\n",
    "# Plot ROC curve\n",
    "<CODE>\n",
    "\n",
    "# Print ROC-AUC score\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cad562",
   "metadata": {},
   "source": [
    "### Understanding Precision-Recall Curve\n",
    "The Precision-Recall curve is especially relevant for churn prediction because:\n",
    "- Precision: Of all customers we predicted would churn, how many actually did?\n",
    "- Recall: Of all actual churners, how many did we catch?\n",
    "\n",
    "This helps balance between:\n",
    "- Not wasting resources on retention efforts (precision)\n",
    "- Not missing potential churners (recall)\n",
    "\n",
    "For telecom churn, high recall might be more important as the cost of losing a customer (false negative) is typically higher than the cost of a retention action (false positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parse predictions (assuming same data structure as before)\n",
    "<CODE>\n",
    "\n",
    "# Calculate Precision-Recall curve\n",
    "<CODE>\n",
    "\n",
    "# Plot\n",
    "<CODE>\n",
    "\n",
    "# Print the score\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1421d69",
   "metadata": {},
   "source": [
    "### Key questions to consider:\n",
    "1. How does your model's performance on the test set compare to the training set? What can you deduce from this comparison? \n",
    "\n",
    "2. Are there obvious differences between the outcomes of metrics like accuracy, precision, and recall? If so, why might you be seeing those differences? \n",
    "\n",
    "3. Given your business situation and goals, which metric(s) is most important for you to consider here? Why?\n",
    "\n",
    "4. Is the outcome for the metric(s) you consider most important sufficient for what you need from a business standpoint? If not, what are some things you might change in your next iteration (in the feature engineering section, which is coming up next)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78762a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the endpoint name\n",
    "endpoint_name = 'your-endpoint-name'\n",
    "\n",
    "# Delete the endpoint\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint '{endpoint_name}' deleted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b651d",
   "metadata": {},
   "source": [
    "# Step 4: Feature engineering\n",
    "\n",
    "You've now gone through one iteration of training and evaluating your model. Given that the outcome you reached for your model the first time probably wasn't sufficient for solving your business problem, what are some things you could change about your data to possibly improve model performance?\n",
    "\n",
    "Lets inspect the dataset once again and decide what can be done to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbdd77-0e1e-4155-93ef-2538bdeeefbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Telco Customer Churn dataset\n",
    "file_path = 'Telco-Customer-Churn.csv'\n",
    "telco_data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the dataset\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba7c9b-fc2a-4572-84e1-69e89f026523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "<CODE>\n",
    "# Plot class distribution\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16774a",
   "metadata": {},
   "source": [
    "There are two main ways to handle imbalanced datasets:\n",
    "\n",
    "- Oversample to add more positive samples\n",
    "    - Random oversampling\n",
    "    - [Synthetic minority oversampling technique (SMOTE)](https://arxiv.org/abs/1106.1813)\n",
    "- Undersample to reduce the negative samples\n",
    "    - Random undersampling\n",
    "    - Generate centroids using clustering methods\n",
    "    \n",
    "We can deduce that there are many negative examples in the dataset.\n",
    "We will use SMOTE to increase the number of positive examples. We will seperate the features and target, do the split of the data and then check the class distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd771d48-2262-4422-a72e-1ca4bcf6f743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d83f43-1f9a-4ded-a81f-1692fec7b4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target\n",
    "<CODE>\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = <CODE>\n",
    "\n",
    "# Check class distribution in training data before SMOTE\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c94df-190d-4e0e-ab75-eebd243c2c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d29bc-ea45-4960-ba6e-6daa034cc332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the class distribution after SMOTE\n",
    "<CODE>\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89fbb6a7-562c-47fb-a5cf-bccf166d1f24",
   "metadata": {},
   "source": [
    "Let us convert the data in numeric format to be used with Sagemaker's built-in algorithm LinearLearner.We will then save the data as a dense tensor in Protobuf format which is optimized for Sagemaker training jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a21154-d459-485c-a5e6-328ec0e7b9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved: 1216992 bytes\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.common import write_numpy_to_dense_tensor\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Convert training data to NumPy arrays in float32 format\n",
    "X_train_np = <CODE> # Convert features\n",
    "y_train_np = <CODE> # Convert labels\n",
    "\n",
    "# Save as a protobuf file\n",
    "train_file = 'train_data'\n",
    "with open(train_file, 'wb') as f:\n",
    "    write_numpy_to_dense_tensor(f, X_train_np, y_train_np)\n",
    "\n",
    "# Check file size for validation\n",
    "print(f\"Training data saved: {os.path.getsize(train_file)} bytes\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32790513-f352-4bf0-a588-c2076fd5f4db",
   "metadata": {},
   "source": [
    "Upload this data to your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f7220-2ffe-4167-aa9c-1c385b614f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data S3 path: s3://pranav-churn1/linear-learner-smote/train/train_data\n"
     ]
    }
   ],
   "source": [
    "train_data_s3_path = sagemaker_session.upload_data(\n",
    "    path=train_file,\n",
    "    bucket='<LabBucketName>',\n",
    "    key_prefix='linear-learner-smote/train'\n",
    ")\n",
    "print(\"Training data S3 path:\", train_data_s3_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7153d7",
   "metadata": {},
   "source": [
    "Define LinearLearner with instance count 1 and type as ml.m5.large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee89e9b-2af9-4e24-89a3-00c3ddaae003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate LinearLearner\n",
    "linear_learner = LinearLearner(\n",
    "    role=role,\n",
    "    instance_count=<CODE>,\n",
    "    instance_type='<CODE>',\n",
    "    predictor_type='<CODE>',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'feature_dim': feature_dim,\n",
    "        'epochs': 50,            # Fixed epochs\n",
    "        'optimizer': 'adam',     # Fixed optimizer\n",
    "        'mini_batch_size': 200,  # Fixed mini_batch_size\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925039b8",
   "metadata": {},
   "source": [
    "Define Sagemaker session and bucket for model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5df39-3ac5-4c06-bf69-b6b141af7b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# S3 bucket for model artifacts\n",
    "bucket = '<LabBucketName>'\n",
    "prefix = 'linear-learner-churn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9fe4f-1a53-4051-8304-bada3b071940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "# Combine features and labels into protobuf format\n",
    "<CODE>\n",
    "\n",
    "\n",
    "# Upload the data to S3\n",
    "<CODE>\n",
    "\n",
    "# Create the S3 path for your training data\n",
    "<CODE>\n",
    "\n",
    "# Create TrainingInput object\n",
    "<CODE>\n",
    "\n",
    "# Now fit the model using the new input format\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32f2ff37-edb8-4d85-ae0e-135b56359d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: linear-learner-2024-11-27-07-11-01-826\n",
      "INFO:sagemaker:Creating endpoint-config with name linear-learner-2024-11-27-07-11-01-826\n",
      "INFO:sagemaker:Creating endpoint with name linear-learner-2024-11-27-07-11-01-826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model\n",
    "predictor = linear_learner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1d95f",
   "metadata": {},
   "source": [
    "Serialize the features in CSV format and display the predictions. Use a threshold of 0.5 for the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1ab7f-3537-4b91-a081-e29e1e18ee75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Serialize test features into CSV format\n",
    "<CODE>\n",
    "\n",
    "# Verify the serialized CSV data\n",
    "print(type(test_csv_data))  # Ensure this is a string\n",
    "print(test_csv_data[:500])  # Preview first 500 characters\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Create a predictor for the endpoint\n",
    "<CODE>\n",
    "\n",
    "# Perform inference\n",
    "<CODE>\n",
    "\n",
    "\n",
    "# Example raw predictions (byte string from SageMaker endpoint)\n",
    "raw_predictions = predictions\n",
    "# Step 1: Decode and parse the byte string\n",
    "decoded_predictions = <CODE>\n",
    "parsed_predictions = <CODE>\n",
    "\n",
    "# Step 2: Extract scores and predicted labels\n",
    "predictions_list = <CODE>\n",
    "scores = <CODE>\n",
    "predicted_labels = <CODE>\n",
    "\n",
    "# Step 3: Convert scores to binary labels using a threshold\n",
    "threshold = 0.5\n",
    "y_pred = <CODE>\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", scores[0])\n",
    "print(\"Predicted Labels (from model):\", predicted_labels[0])\n",
    "print(\"Binary Labels (custom threshold):\", y_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5ed47",
   "metadata": {},
   "source": [
    "Plot the confusion and classification matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003acf7-c028-4c74-9454-e63b59e578a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    <CODE>\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "    <CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f34ee",
   "metadata": {},
   "source": [
    " Plot ROC-AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66709dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144eca2c",
   "metadata": {},
   "source": [
    " Plot precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1dfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "<CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce375bb",
   "metadata": {},
   "source": [
    "What can you deduce from the output above? Has the performance improved for the model?\n",
    "Does it meet your business goals?\n",
    "Are you aware about any more techniques that can improve the model performance?\n",
    "Optional Step: Apply hyperparameter tuning to above solution to check if it can improve the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacb581",
   "metadata": {},
   "source": [
    "# Step 5: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3cfae",
   "metadata": {},
   "source": [
    "When you build complex machine learning systems like deep learning neural networks, exploring all of the possible combinations is impractical. Hyperparameter tuning can accelerate your productivity by trying many variations of a model. It looks for the best model automatically by focusing on the most promising combinations of hyperparameter values within the ranges that you specify. To get good results, you must choose the right ranges to explore.\n",
    "\n",
    "Refer to this [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) to explore hyperparameter tuning strategies available in Amazon SageMaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import numpy as np\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "from sagemaker.amazon.common import write_numpy_to_dense_tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the SMOTE data into training and validation sets\n",
    "<CODE>\n",
    "\n",
    "# Convert to NumPy arrays in float32 format\n",
    "<CODE>\n",
    "\n",
    "# Save training data to a local file in RecordIO protobuf format\n",
    "<CODE>\n",
    "\n",
    "# Save validation data to a local file in RecordIO protobuf format\n",
    "<CODE>\n",
    "\n",
    "# Upload the data to S3\n",
    "<CODE>\n",
    "\n",
    "# Specify the data channels\n",
    "<CODE>\n",
    "\n",
    "# Define hyperparameter ranges (only tunable hyperparameters)\n",
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.0001, 0.2),\n",
    "    'l1': ContinuousParameter(0.0, 1.0),\n",
    "    'wd': ContinuousParameter(0.0, 1.0),  # 'wd' is weight decay (L2 regularization)\n",
    "    'use_bias': CategoricalParameter(['True', 'False']),  # Use strings for booleans\n",
    "    'positive_example_weight_mult': ContinuousParameter(0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Define the objective metric\n",
    "objective_metric_name = 'validation:binary_classification_accuracy'\n",
    "\n",
    "# Metric definitions for parsing the logs\n",
    "metric_definitions = [\n",
    "    {'Name': 'validation:binary_classification_accuracy', 'Regex': 'validation: BinaryClassificationAccuracy=([0-9\\\\.]+)'},\n",
    "]\n",
    "\n",
    "# Create a HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=linear_learner,\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    objective_type='Maximize',  # We aim to maximize accuracy\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_jobs=20,                # Total number of training jobs\n",
    "    max_parallel_jobs=2         # How many training jobs can run in parallel\n",
    ")\n",
    "\n",
    "# Start hyperparameter tuning\n",
    "tuner.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the best model\n",
    "best_estimator = tuner.best_estimator()\n",
    "predictor = best_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83307114",
   "metadata": {},
   "source": [
    "Now perform similar evaluation techniques as previous steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbdb5c",
   "metadata": {},
   "source": [
    "### Final Model Analysis & Conclusions\n",
    "\n",
    "After hyperparameter tuning, it's crucial to analyze how our model performance changed:\n",
    "\n",
    "1. Impact of Hyperparameter Tuning:\n",
    "   - While we found the \"best\" model through tuning, our metrics show that the improvements were modest\n",
    "   - This suggests that the basic model architecture might be a limiting factor, not just the parameters\n",
    "   - Sometimes simpler models have an inherent performance ceiling that tuning alone can't overcome\n",
    "\n",
    "2. Evaluation Metrics Review:\n",
    "   - **Confusion Matrix**: Still shows imbalance in prediction capabilities\n",
    "     - The model remains better at identifying non-churners than churners\n",
    "     - This is a common challenge in churn prediction due to class imbalance\n",
    "   \n",
    "   - **ROC-AUC**: A good but not excellent score\n",
    "     - Shows model performs better than random but has room for improvement\n",
    "     - Suggests we might need to look beyond just tuning hyperparameters\n",
    "   \n",
    "   - **Precision-Recall**: Trade-off remains significant\n",
    "     - Difficulty in simultaneously achieving high precision and recall\n",
    "     - Indicates we might need different approaches for better balance\n",
    "\n",
    "3. Next Steps to Consider:\n",
    "   - Feature engineering might have more impact than further parameter tuning\n",
    "   - Consider trying different model architectures (e.g., ensemble methods, deep learning)\n",
    "   - Collect more data or different types of features\n",
    "   - Address class imbalance through advanced sampling techniques\n",
    "   - Consider business-specific cost functions instead of standard metrics\n",
    "\n",
    "Remember: In real-world churn prediction, a modest improvement in model performance can translate to significant business value. The goal isn't always to achieve perfect metrics, but to create a model that provides actionable insights and positive ROI for retention efforts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
